import matplotlib as plt
import numpy as np
import sympy as sym
from matplotlib import pyplot

def objective(x):
    return (x+3)**2

def derivative(x):
    return 2*(x+3)

def gradient_descent(alpha,start,max_iter):
    x_list = list()
    x = start
    for i in range(max_iter):
        gradient = derivative(x)
        x = x-(alpha*gradient)
        x_list.append(x)
    return x_list

x = sym.symbols('x')
expr = (x+3)**2.0
grad = sym.Derivative(expr,x)
print("{}".format(grad.doit()))
grad.doit().subs(x,2)

alpha = 0.1
start = 2
max_iter = 30
x = sym.symbols('x')
expr = (x+3)**2

x_cordinate = np.linspace(-15,15,100)
pyplot.plot(x_cordinate,objective(x_cordinate))
pyplot.plot(2,objective(2),'ro')

x = gradient_descent(alpha,start,max_iter)
x_cordinate = np.linspace(-5,5,100)
pyplot.plot(x_cordinate,objective(x_cordinate))
x_arr = np.array(x)
pyplot.plot(x_arr,objective(x_arr),'.-',color = "red")
pyplot.show()


#Initialize Parameters
#cur_x = 2
#rate = 0.01
#precision = 0.000001
#previous_step_size = 1
#max_iters = 1000
#iters = 0
#df = lambda x : 2 * (x + 3) #Gradient of our function i.e (x + 3)Â²

#Run a loop to perform gradient Descent
#while previous_step_size > precision and iters < max_iters:
#    prev_x = cur_x
#    cur_x -= rate * df(prev_x)
#    previous_step_size = abs(prev_x - cur_x)
#    iters += 1
#print("Local Minima Occurs at :",cur_x)
